{
  "overview": {
    "project_name": "ai-congress",
    "description": "LLM swarm of autonomous agents using Python and Ollama that acts like congress with ensemble decision-making",
    "key_features": [
      "Multiple Ollama models working as ensemble (congress voting system)",
      "Weighted voting based on model accuracy/performance metrics",
      "Two swarm modes: multi-model & multi-request (with temperature variation)",
      "Beautiful web UI inspired by Open WebUI",
      "CLI interface with Rich library for pretty output",
      "High verbosity for debugging",
      "Chat UI with selectable model list",
      "Prioritize lightweight models for efficiency"
    ],
    "tech_stack": {
      "backend": [
        "Python 3.11+",
        "FastAPI",
        "Ollama Python SDK",
        "asyncio",
        "websockets"
      ],
      "frontend": [
        "Svelte",
        "Vite",
        "Tailwind CSS"
      ],
      "cli": [
        "Rich",
        "Click or Typer"
      ],
      "database": [
        "SQLite (for storing model performance)",
        "Redis (optional for caching)"
      ],
      "deployment": [
        "Docker",
        "Docker Compose"
      ]
    }
  },
  "architecture": {
    "components": [
      {
        "name": "Model Registry",
        "purpose": "Track available Ollama models and their performance metrics",
        "responsibilities": [
          "List available models",
          "Store accuracy scores",
          "Calculate voting weights"
        ]
      },
      {
        "name": "Swarm Orchestrator",
        "purpose": "Coordinate multiple LLM requests and aggregate responses",
        "responsibilities": [
          "Manage concurrent requests to multiple models",
          "Handle temperature-based sampling for diversity",
          "Implement voting mechanisms (majority, weighted)",
          "Aggregate and rank responses"
        ]
      },
      {
        "name": "Voting Engine",
        "purpose": "Implement ensemble decision-making algorithms",
        "responsibilities": [
          "Weighted majority voting",
          "Confidence-based voting",
          "Boosting-based ensemble",
          "Response similarity clustering"
        ]
      },
      {
        "name": "Web UI (Svelte)",
        "purpose": "Beautiful chat interface for user interaction",
        "responsibilities": [
          "Real-time chat with streaming responses",
          "Model selection interface",
          "Voting visualization",
          "Performance metrics dashboard"
        ]
      },
      {
        "name": "CLI Interface",
        "purpose": "Command-line access with Rich formatting",
        "responsibilities": [
          "Interactive REPL for chat",
          "Model management commands",
          "Verbose logging output",
          "Configuration management"
        ]
      },
      {
        "name": "API Layer (FastAPI)",
        "purpose": "RESTful and WebSocket endpoints",
        "responsibilities": [
          "HTTP endpoints for model management",
          "WebSocket for streaming chat",
          "Ollama proxy/aggregation"
        ]
      }
    ]
  },
  "implementation_plan": {
    "phases": [
      {
        "phase": 1,
        "name": "Core Infrastructure",
        "duration": "Week 1",
        "tasks": [
          "Project structure setup with best practices",
          "Ollama integration and model listing",
          "Basic model registry with SQLite",
          "Simple CLI with Rich for testing",
          "Async request handling setup"
        ]
      },
      {
        "phase": 2,
        "name": "Swarm Logic",
        "duration": "Week 2",
        "tasks": [
          "Implement concurrent model querying with asyncio",
          "Temperature-based sampling for multi-request mode",
          "Basic voting mechanisms (majority vote)",
          "Weighted voting based on accuracy scores",
          "Response aggregation and ranking"
        ]
      },
      {
        "phase": 3,
        "name": "FastAPI Backend",
        "duration": "Week 3",
        "tasks": [
          "FastAPI application setup",
          "REST endpoints for model management",
          "WebSocket endpoint for streaming chat",
          "Integration with swarm orchestrator",
          "Error handling and logging"
        ]
      },
      {
        "phase": 4,
        "name": "Web UI (Svelte)",
        "duration": "Week 4",
        "tasks": [
          "Svelte project setup with Vite",
          "Chat interface component (inspired by Open WebUI)",
          "Model selector with checkboxes",
          "Streaming response display",
          "Voting visualization (who voted for what)",
          "Tailwind CSS styling"
        ]
      },
      {
        "phase": 5,
        "name": "CLI Enhancement",
        "duration": "Week 5",
        "tasks": [
          "Advanced Rich formatting for responses",
          "Verbose logging modes",
          "Interactive model selection",
          "Progress indicators for swarm requests",
          "Configuration file support (YAML/JSON)"
        ]
      },
      {
        "phase": 6,
        "name": "Performance & Testing",
        "duration": "Week 6",
        "tasks": [
          "Benchmark model accuracy collection",
          "Performance optimization for concurrent requests",
          "Unit tests for voting algorithms",
          "Integration tests for API",
          "Docker containerization"
        ]
      }
    ]
  },
  "algorithms": {
    "voting_mechanisms": [
      {
        "name": "Weighted Majority Vote",
        "description": "Each model's vote weighted by its accuracy score",
        "formula": "weighted_score = \u03a3(model_accuracy_i * vote_i)",
        "use_case": "Primary voting mechanism for final answer selection"
      },
      {
        "name": "Confidence-Based Voting",
        "description": "Weight votes by model's confidence in its answer",
        "formula": "confidence_score = model_weight * response_probability",
        "use_case": "When models provide probability scores"
      },
      {
        "name": "Temperature Sampling Ensemble",
        "description": "Query same model multiple times with different temperatures",
        "parameters": "temperature range: 0.0 to 1.6, typically 0.3, 0.7, 1.0",
        "use_case": "Single model swarm for diverse responses"
      },
      {
        "name": "Majority Voting",
        "description": "Simple majority wins, all models equal weight",
        "formula": "most_common(responses)",
        "use_case": "Baseline comparison or when no accuracy data available"
      }
    ]
  },
  "lightweight_models": {
    "ultra_light": [
      {
        "name": "tinyllama:1.1b",
        "size": "1.1B",
        "ram": "~1GB",
        "use": "Ultra-fast responses"
      },
      {
        "name": "phi3:3.8b",
        "size": "3.8B",
        "ram": "~2.5GB",
        "use": "Best quality/size ratio"
      },
      {
        "name": "gemma2:2b",
        "size": "2B",
        "ram": "~2GB",
        "use": "Multilingual support"
      }
    ],
    "light": [
      {
        "name": "mistral:7b",
        "size": "7B",
        "ram": "~4GB",
        "use": "Balanced performance"
      },
      {
        "name": "llama3.2:3b",
        "size": "3B",
        "ram": "~3GB",
        "use": "Good general purpose"
      },
      {
        "name": "qwen2.5:7b",
        "size": "7B",
        "ram": "~5GB",
        "use": "Strong reasoning"
      },
      {
        "name": "phi3:7b",
        "size": "7B",
        "ram": "~4GB",
        "use": "Efficient 7B option"
      }
    ],
    "medium": [
      {
        "name": "llama3.1:8b",
        "size": "8B",
        "ram": "~6GB",
        "use": "High quality responses"
      },
      {
        "name": "mistral:13b",
        "size": "13B",
        "ram": "~8GB",
        "use": "Complex tasks"
      },
      {
        "name": "codellama:13b",
        "size": "13B",
        "ram": "~8GB",
        "use": "Code generation"
      }
    ]
  },
  "resources": {
    "ollama": [
      "https://github.com/ollama/ollama - Ollama main repository",
      "https://github.com/ollama/ollama-python - Official Python library",
      "https://ollama.com/library - Model library",
      "https://docs.ollama.com/ - Official documentation"
    ],
    "open_webui": [
      "https://github.com/open-webui/open-webui - Main repository for UI inspiration",
      "https://docs.openwebui.com/ - Documentation",
      "https://github.com/open-webui/open-webui/tree/main/src - Frontend source code"
    ],
    "fastapi": [
      "https://fastapi.tiangolo.com/ - Official docs",
      "https://fastapi.tiangolo.com/advanced/websockets/ - WebSocket guide",
      "https://fastapi.tiangolo.com/advanced/custom-response/#streamingresponse - Streaming responses"
    ],
    "svelte": [
      "https://svelte.dev/docs - Svelte documentation",
      "https://kit.svelte.dev/docs - SvelteKit docs",
      "https://tailwindcss.com/docs - Tailwind CSS"
    ],
    "rich": [
      "https://github.com/Textualize/rich - Rich library",
      "https://rich.readthedocs.io/ - Documentation",
      "https://github.com/Textualize/rich-cli - Rich CLI examples"
    ],
    "ensemble_learning": [
      "https://arxiv.org/abs/2312.12036 - LLM ensemble paper",
      "https://scikit-learn.org/stable/modules/ensemble.html - Ensemble methods",
      "https://docs.swarms.world/en/latest/swarms/concept/multi_agent_architectures/ - Multi-agent architectures"
    ],
    "benchmarks": [
      "https://huggingface.co/spaces/open-llm-leaderboard/open_llm_leaderboard - Open LLM Leaderboard",
      "https://collabnix.com/best-ollama-models-2025/ - Ollama model comparisons",
      "MMLU, HumanEval, GSM8K benchmarks for model accuracy"
    ]
  }
}